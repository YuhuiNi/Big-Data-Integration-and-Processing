# Big-Data-Integration-and-Processing

This course is part of the Big Data Specialization provided by UCSanDiego.

Through this course, we are able to:

* Retrieve data from example database and big data management systems 
* Describe the connections between data management operations and the big data processing patterns needed to utilize them in large-scale analytical applications
* Identify when a big data problem needs data integration
* Execute simple big data integration and processing on Hadoop and Spark platforms

Skills we will gain:

* Mongodb
* Splunk
* Apache Spark

This repository covers the following things:

#### 1.[Lecture notes](https://github.com/YuhuiNi/Big-Data-Integration-and-Processing/tree/master/slices)

#### 2.Code Assignments
- [Analzying Tweets with Spark](https://github.com/YuhuiNi/Big-Data-Integration-and-Processing/blob/master/code%20assignment/SoccerTweetAnalysis.ipynb)   
- [Exploring SparkSQL and Spark Dataframes](https://github.com/YuhuiNi/Big-Data-Integration-and-Processing/blob/master/code%20assignment/spark-example-sparksql.ipynb)  
- [Spark & Hadoop Wordcount (Pyspark)](https://github.com/YuhuiNi/Big-Data-Integration-and-Processing/blob/master/code%20assignment/spark-example-wc.ipynb)
- [Spark MLlib example using Kmeans Clustering and RandomRDDs](https://github.com/YuhuiNi/Big-Data-Integration-and-Processing/blob/master/code%20assignment/spark-example-kmeans.ipynb)  
- [Analzying Sensor Data with Spark Streaming](https://github.com/YuhuiNi/Big-Data-Integration-and-Processing/blob/master/code%20assignment/spark-example-streaming.ipynb)
- [Querying and Exporting from MongoDB](https://github.com/YuhuiNi/Big-Data-Integration-and-Processing/blob/master/code%20assignment/Querying-and-Exporting-from-MongoDB.md)  




